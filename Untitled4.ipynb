{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hsy8I7C5mok",
        "outputId": "0106e4df-7099-4a42-d1f5-de38a936e125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Type: Regression\n",
            "Target Variable: petal_width\n",
            "Regression Type: regression\n",
            "Partitioning Enabled: True\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def parse_target_config(json_data):\n",
        "    # Extracting the 'target' section from the JSON\n",
        "    target_config = json_data.get(\"target\", {})\n",
        "\n",
        "    # Reading the required information\n",
        "    prediction_type = target_config.get(\"prediction_type\", \"Not specified\")\n",
        "    target_variable = target_config.get(\"target\", \"Not specified\")\n",
        "    regression_type = target_config.get(\"type\", \"Not specified\")\n",
        "    partitioning = target_config.get(\"partitioning\", False)\n",
        "\n",
        "    # Printing the extracted information\n",
        "    print(f\"Prediction Type: {prediction_type}\")\n",
        "    print(f\"Target Variable: {target_variable}\")\n",
        "    print(f\"Regression Type: {regression_type}\")\n",
        "    print(f\"Partitioning Enabled: {partitioning}\")\n",
        "\n",
        "# Example JSON input\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"target\": {\n",
        "    \"prediction_type\": \"Regression\",\n",
        "    \"target\": \"petal_width\",\n",
        "    \"type\": \"regression\",\n",
        "    \"partitioning\": true\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the provided JSON\n",
        "json_data = json.loads(json_input)\n",
        "parse_target_config(json_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Your JSON input as a string\n",
        "json_input = \"\"\"\n",
        "{\n",
        "  \"feature_handling\": {\n",
        "    \"sepal_length\": {\n",
        "      \"feature_name\": \"sepal_length\",\n",
        "      \"is_selected\": true,\n",
        "      \"feature_variable_type\": \"numerical\",\n",
        "      \"feature_details\": {\n",
        "        \"numerical_handling\": \"Keep as regular numerical feature\",\n",
        "        \"rescaling\": \"No rescaling\",\n",
        "        \"make_derived_feats\": false,\n",
        "        \"missing_values\": \"Impute\",\n",
        "        \"impute_with\": \"Average of values\",\n",
        "        \"impute_value\": 0\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the JSON input to get the configuration\n",
        "feature_config = json.loads(json_input)\n",
        "\n",
        "# Function to apply imputation based on the feature configuration\n",
        "def apply_imputation(df, feature_config):\n",
        "    for feature, config in feature_config[\"feature_handling\"].items():\n",
        "        if config[\"feature_details\"][\"missing_values\"] == \"Impute\":\n",
        "            if config[\"feature_details\"][\"impute_with\"] == \"Average of values\":\n",
        "                # Calculate the average without considering NaN values\n",
        "                avg_value = df[feature].mean()\n",
        "                # Fill NaN values with the calculated average\n",
        "                df[feature].fillna(avg_value, inplace=True)\n",
        "            # Extend this block to handle other imputation methods as needed\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('iris.csv')\n",
        "\n",
        "# Apply the imputation to the DataFrame based on the configuration\n",
        "apply_imputation(df, feature_config)\n",
        "\n",
        "# Display the DataFrame to verify the imputation\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnzDMgN26D-V",
        "outputId": "e2606a6a-a58b-4530-95cf-4fd451b73f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Assuming df is your DataFrame and target_variable is your target column's name\n",
        "def apply_feature_reduction(df, target_variable, config):\n",
        "    method = config[\"feature_reduction_method\"]\n",
        "    reduced_df = df.copy()\n",
        "\n",
        "    # No Reduction\n",
        "    if config[\"No Reduction\"][\"is_selected\"]:\n",
        "        # Assuming 'No Reduction' simply means limiting the number of features without any specific method\n",
        "        num_features = config[\"No Reduction\"][\"num_of_features_to_keep\"]\n",
        "        reduced_df = reduced_df.iloc[:, :num_features]\n",
        "\n",
        "    # Correlation with Target\n",
        "    elif config[\"Correlation with target\"][\"is_selected\"]:\n",
        "        num_features = config[\"Correlation with target\"][\"num_of_features_to_keep\"]\n",
        "        corr_scores = {col: pearsonr(df[col], df[target_variable])[0] for col in df.columns if df[col].dtype != 'object' and col != target_variable}\n",
        "        sorted_features = sorted(corr_scores, key=corr_scores.get, reverse=True)[:num_features]\n",
        "        reduced_df = df[sorted_features + [target_variable]]\n",
        "\n",
        "    # Tree-based\n",
        "    elif config[\"Tree-based\"][\"is_selected\"]:\n",
        "        num_features = config[\"Tree-based\"][\"num_of_features_to_keep\"]\n",
        "        clf = ExtraTreesClassifier(n_estimators=config[\"Tree-based\"][\"num_of_trees\"])\n",
        "        clf = clf.fit(df.drop(target_variable, axis=1), df[target_variable])\n",
        "        importances = clf.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1][:num_features]\n",
        "        selected_features = df.columns[indices]\n",
        "        reduced_df = df[selected_features.tolist() + [target_variable]]\n",
        "\n",
        "    # PCA\n",
        "    elif config[\"Principal Component Analysis\"][\"is_selected\"]:\n",
        "        num_features = config[\"Principal Component Analysis\"][\"num_of_features_to_keep\"]\n",
        "        pca = PCA(n_components=num_features)\n",
        "        principalComponents = pca.fit_transform(df.drop(target_variable, axis=1))\n",
        "        reduced_df = pd.DataFrame(data = principalComponents, columns = [f'PC{i}' for i in range(1, num_features + 1)])\n",
        "        reduced_df[target_variable] = df[target_variable]\n",
        "\n",
        "    return reduced_df\n",
        "\n",
        "# Example usage:\n",
        "json_config = {\n",
        "  \"feature_reduction_method\": \"Correlation with target\",\n",
        "  \"No Reduction\": {\"is_selected\": True, \"num_of_features_to_keep\": 5},\n",
        "  \"Correlation with target\": {\"is_selected\": False, \"num_of_features_to_keep\": 8},\n",
        "  \"Tree-based\": {\"is_selected\": False, \"num_of_features_to_keep\": 0, \"depth_of_trees\": 0, \"num_of_trees\": 0},\n",
        "  \"Principal Component Analysis\": {\"is_selected\": False, \"num_of_features_to_keep\": 0},\n",
        "}\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('iris.csv')\n",
        "target_variable = 'YourTargetColumnNameHere'\n",
        "\n",
        "# Apply feature reduction\n",
        "reduced_df = apply_feature_reduction(df, target_variable, json_config)\n",
        "\n",
        "# Check the result\n",
        "print(reduced_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChsItan_ADUp",
        "outputId": "cb94cd65-cd57-4bfc-c90e-9f61e230f264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Sample JSON configuration\n",
        "json_config = \"\"\"\n",
        "{\n",
        "  \"prediction_type\": \"Classification\",\n",
        "  \"models\": {\n",
        "    \"LogisticRegression\": {\n",
        "      \"model_name\": \"LogisticRegression\",\n",
        "      \"is_selected\": true,\n",
        "      \"parallelism\": 2,\n",
        "      \"min_iter\": 30,\n",
        "      \"max_iter\": 50,\n",
        "      \"min_regparam\": 0.5,\n",
        "      \"max_regparam\": 0.8,\n",
        "      \"min_elasticnet\": 0.5,\n",
        "      \"max_elasticnet\": 0.8\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Function to parse JSON and instantiate models\n",
        "def instantiate_model_from_json(json_str):\n",
        "    config = json.loads(json_str)\n",
        "    models = []\n",
        "\n",
        "    if config[\"prediction_type\"] == \"Classification\":\n",
        "        # For each model configuration\n",
        "        for model_name, model_config in config[\"models\"].items():\n",
        "            if model_config[\"is_selected\"]:\n",
        "                if model_name == \"LogisticRegression\":\n",
        "                    # Example: Instantiate logistic regression with averaged parameters\n",
        "                    # Adjust the instantiation as needed based on the parameters you want to use\n",
        "                    lr = LogisticRegression(\n",
        "                        max_iter=int((model_config[\"min_iter\"] + model_config[\"max_iter\"]) / 2),\n",
        "                        C=1.0 / ((model_config[\"min_regparam\"] + model_config[\"max_regparam\"]) / 2),  # Inverse of regularization strength\n",
        "                        # L1 ratio or other parameters related to elastic net can be set similarly\n",
        "                    )\n",
        "                    models.append(lr)\n",
        "                # Extend with elif blocks for other classification models as needed\n",
        "    elif config[\"prediction_type\"] == \"Regression\":\n",
        "        # Instantiate regression models similarly, for example:\n",
        "        pass  # Add logic for regression models here\n",
        "\n",
        "    return models\n",
        "\n",
        "# Example usage\n",
        "models = instantiate_model_from_json(json_config)\n",
        "for model in models:\n",
        "    print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYSDR5DyCAMf",
        "outputId": "ec32a50f-fffc-4f27-c732-6c193572ed2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1.5384615384615383, max_iter=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFVFAH7bDcFo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}